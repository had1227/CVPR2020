# CVPR2020
[CVPR2020 paper list](http://openaccess.thecvf.com/CVPR2020.py)

[CVPR2020 conference page](http://cvpr20.com/)

## Table of Contents
  - [Visual-Language Grounding](#visual-language-grounding)
    - [Video-Language Grounding](#video-language-grounding)
    - [Object-Referring Grounding](#object-referring-grounding)
  - [Visual Navigation](#visual-navigation)
  - [Object Detection](#object-detection)
    - [Domain Adaptation Object Detection](#domain-adaptation-object-detection)
  - [Pose Estimation](#pose-estimation)
  - [Feature Detection](#feature-detection)
  - [Sim-to-Real](#sim-to-real)
  - [Human-Object Interaction](#human-object-interaction)
  - [3D From a Single Image](#3d-from-a-single-image)
  - [Motion and Tracking](#motion-and-tracking)


### Visual-Language Grounding:

1. Mihir Prabhudesai, Hsiao-Yu Fish Tung, Syed Ashar Javed, et al. **Embodied Language Grounding With 3D Visual Feature Representations.** [[Paper]](https://arxiv.org/pdf/1910.01210.pdf) - Nuri

1. Yuanen Zhou, Meng Wang, Daqing Liu, Zhenzhen Hu, Hanwang Zhang, **More Grounded Image Captioning by Distilling Image-Text Matching Model** [[Paper]](https://arxiv.org/pdf/2004.00390.pdf) [[Code]](https://github.com/YuanEZhou/Grounded-Image-Captioning) - Nuri

### Video-Language Grounding

1. Gunnar A. Sigurdsson, Jean-Baptiste Alayrac, Aida Nematzadeh, Lucas Smaira, Mateusz Malinowski, Jo√£o Carreira, Phil Blunsom, Andrew Zisserman, **Visual Grounding in Video for Unsupervised Word Translation** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Sigurdsson_Visual_Grounding_in_Video_for_Unsupervised_Word_Translation_CVPR_2020_paper.pdf) [[Code]](https://github.com/gsig/visual-grounding) - Nuri

1. Runhao Zeng, Haoming Xu, Wenbing Huang, Peihao Chen, Mingkui Tan, Chuang Gan, **Dense Regression Network for Video Grounding** [[Paper]](https://arxiv.org/pdf/2004.03545.pdf) - Nuri

1. Zhu Zhang, Zhou Zhao, Yang Zhao, Qi Wang, Huasheng Liu, Lianli Gao, **Where Does It Exist: Spatio-Temporal Video Grounding for Multi-Form Sentences** [[Paper]](https://arxiv.org/pdf/2001.06891.pdf) [[Dataset]](https://github.com/Guaranteer/VidSTG-Dataset) - Nuri

1. Arka Sadhu, Kan Chen, Ram Nevatia, **Video Object Grounding Using Semantic Roles in Language Description** [[Paper]](https://arxiv.org/pdf/2003.10606.pdf) [[Code]](https://github.com/TheShadow29/vognet-pytorch) - Nuri

### Object Referring Grounding

1. Sibei Yang, Guanbin Li, Yizhou Yu **Graph-Structured Referring Expression Reasoning in the Wild**, Oral [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Graph-Structured_Referring_Expression_Reasoning_in_the_Wild_CVPR_2020_paper.pdf) [[Code]](https://github.com/sibeiyang/sgmn) [[video]](http://d1tz9o43mm5y8k.cloudfront.net/CVPR20/CVPR20/2703/2703-oral.mp4) - [[Nuri]](nuri.md/#graph-structured-referring-expression-reasoning-in-the-wild))

2. Zhibo Yang, Lihan Huang, Yupei Chen, Zijun Wei, Seoyoung Ahn, Gregory Zelinsky, Dimitris Samaras, Minh Hoai	**Predicting Goal-Directed Human Attention Using Inverse Reinforcement Learning** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_Predicting_Goal-Directed_Human_Attention_Using_Inverse_Reinforcement_Learning_CVPR_2020_paper.pdf) - Hwiyeon

### Visual Navigation:
1. Mohit Shridhar, Jesse Thomason, Daniel Gordon, Yonatan Bisk, Winson Han, Roozbeh Mottaghi, Luke Zettlemoyer, Dieter Fox, **ALFRED: A Benchmark for Interpreting Grounded Instructions for Everyday Tasks** [[Paper]](https://arxiv.org/pdf/1912.01734.pdf) [[Code]](https://github.com/askforalfred/alfred) [[Project Page]](https://askforalfred.com/) [[PresentationVideo]](https://youtu.be/1XoRLNmXffo) - [[Nuri]](nuri.md/#alfred-a-benchmark-for-interpreting-grounded-instructions-for-everyday-tasks)

2. Devendra Singh Chaplot, Ruslan Salakhutdinov, Abhinav Gupta, Saurabh Gupta, **Neural Topological SLAM for Visual Navigation** [[Paper]](http://www.cs.cmu.edu/~dchaplot/papers/cvpr20_neural_topological_slam.pdf) [[Project Page]](http://www.cs.cmu.edu/~dchaplot/projects/neural-topological-slam.html) - Yunho

3. Yi Zhu, Fengda Zhu, Zhaohuan Zhan, Bingqian Lin, Jianbin Jiao, Xiaojun Chang, Xiaodan Liang, **Vision-Dialog Navigation by Exploring Cross-Modal Memory** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_Vision-Dialog_Navigation_by_Exploring_Cross-Modal_Memory_CVPR_2020_paper.pdf) - Obin

4. Thomas Roddick, Roberto Cipolla	**Predicting Semantic Map Representations From Images Using Pyramid Occupancy Networks** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Roddick_Predicting_Semantic_Map_Representations_From_Images_Using_Pyramid_Occupancy_Networks_CVPR_2020_paper.pdf) - Hwiyeon

5. Fengda Zhu, Yi Zhu, Xiaojun Chang, Xiaodan Liang	**Vision-Language Navigation With Self-Supervised Auxiliary Reasoning Tasks** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zhu_Vision-Language_Navigation_With_Self-Supervised_Auxiliary_Reasoning_Tasks_CVPR_2020_paper.pdf) - Hwiyeon

6. Juncheng Li, Xin Wang, Siliang Tang, Haizhou Shi, Fei Wu, Yueting Zhuang, William Yang Wang, **Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Unsupervised_Reinforcement_Learning_of_Transferable_Meta-Skills_for_Embodied_Navigation_CVPR_2020_paper.pdf) - [[Obin]](https://www.notion.so/obstudy/Unsupervised-Reinforcement-Learning-of-Transferable-Meta-Skills-for-Embodied-Navigation-c19c6fb0fb644b54af2b57e5e4d9f3c8)

7. Yuankai Qi, Qi Wu, Peter Anderson, Xin Wang, William Yang Wang, Chunhua Shen, Anton van den Hengel, **REVERIE: Remote Embodied Visual Referring Expression in Real Indoor Environments** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Qi_REVERIE_Remote_Embodied_Visual_Referring_Expression_in_Real_Indoor_Environments_CVPR_2020_paper.pdf) - [[Obin]](https://www.notion.so/obstudy/941787944cf4495d893d91e5c6ffa9ab)

### Object Detection
1. Wu Jialian, Zhou Chunluan, Yang Ming, et al. **Temporal-Context Enhanced Detection of Heavily Occluded Pedestrians.** [[Paper]](https://cse.buffalo.edu/~jsyuan/papers/2020/TFAN.pdf) - Kyungdo

2. Perez-Rua, Juan-Manuel, et al. **Incremental Few-Shot Object Detection.** [[Paper]](https://arxiv.org/pdf/2003.04668.pdf) - Hogun

3. Zhu, Pengkai, Hanxiao Wang, and Venkatesh Saligrama. **Dont Even Look Once: Synthesizing Features for Zero-Shot Detection.** [[Paper]](https://arxiv.org/pdf/1911.07933.pdf) - Hogun

4. Zhibo Yang, Lihan Huang, Yupei Chen, Zijun Wei, Seoyoung Ahn, Gregory Zelinsky, Dimitris Samaras, Minh Hoai. **"Predicting Goal-directed Human Attention Using Inverse Reinforcement Learning"**  [[Paper]](https://arxiv.org/pdf/2005.14310.pdf) [[Code]](https://github.com/cvlab-stonybrook/Scanpath_Prediction) - [[Obin]](https://www.notion.so/obstudy/Predicting-Goal-directed-Human-Attention-Using-IRL-45f2d11189654523a1d53c8f143fa1b9)

5. Chenchen Liu, Yang Jin, Kehan Xu, Guoqiang Gong, Yadong Mu, **Beyond Short-Term Snippet: Video Relation Detection with Spatio-Temporal Global Context** [[Paper](http://openaccess.thecvf.com/content_CVPR_2020/papers/Liu_Beyond_Short-Term_Snippet_Video_Relation_Detection_With_Spatio-Temporal_Global_Context_CVPR_2020_paper.pdf) - Obin

### Domain Adaptation Object Detection
1. Yangtao Zheng, Di Huang, Songtao Liu, Yunhong Wang **Cross-domain Object Detection through Coarse-to-Fine Feature Adaptation** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Zheng_Cross-domain_Object_Detection_through_Coarse-to-Fine_Feature_Adaptation_CVPR_2020_paper.pdf) - Nuri

### Pose Estimation
1. He, Yisheng, et al. **PVN3D: A Deep Point-wise 3D Keypoints Voting Network for 6DoF Pose Estimation.** [[Paper]](https://arxiv.org/pdf/1911.04231.pdf) [[Code]](https://github.com/ethnhe/PVN3D) - Hogun

2. Liu, Xingyu, et al. **KeyPose: Multi-View 3D Labeling and Keypoint Estimationfor Transparent Objects.** [[Paper]](https://arxiv.org/pdf/1912.02805.pdf) [[Project Page]](https://sites.google.com/view/keypose) - Hogun

3. Xiaolong Li, He Wang et al. **ANCSH: Category-Level Articulated Object Pose Estimation.** [[paper]](https://arxiv.org/pdf/1912.11913.pdf) [[Project Page]](https://articulated-pose.github.io/) [[Code]](https://github.com/dragonlong/articulated-pose) - Dohyeong

4. Jingwei Xu, Zhenbo Yu, Bingbing Ni, Jiancheng Yang, Xiaokang Yang, Wenjun Zhang **Deep Kinematics Analysis for Monocular 3D Human Pose Estimation** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Deep_Kinematics_Analysis_for_Monocular_3D_Human_Pose_Estimation_CVPR_2020_paper.pdf) - Seunggyu

### Feature Detection
1. Paul-Edouard Sarlin, et al., **SuperGlue: Learning Feature Matching with Graph Neural Networks.** [[Paper]](https://arxiv.org/pdf/1911.11763.pdf) [[Code]](https://github.com/magicleap/SuperGluePretrainedNetwork) - Yunho

2. Aritra Bhowmik, et al., **Reinforced Feature Points: Optimizing Feature Detection and Description for a High-Level Task.** [[Paper]](https://arxiv.org/pdf/1912.00623.pdf) - Yunho

### Sim-to-Real
1. Kanishka Rao, Chris Harris, Alex Irpan, Sergey Levine, Julian Ibarz, and Mohi Khansari **RL-CycleGAN: Reinforcement Learning Aware Simulation-To-Real.** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Rao_RL-CycleGAN_Reinforcement_Learning_Aware_Simulation-to-Real_CVPR_2020_paper.pdf) - Yunho

### Human-Object Interaction

1. Oytun Ulutan, A S M Iftekhar, B. S. Manjunath	**VSGNet: Spatial Attention Network for Detecting Human Object Interactions Using Graph Convolutions** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Ulutan_VSGNet_Spatial_Attention_Network_for_Detecting_Human_Object_Interactions_Using_CVPR_2020_paper.pdf) [[Code]](https://github.com/ASMIftekhar/VSGNet) - Nuri

### 3D From a Single Image

1. Zhenxing Mi, Yiming Luo, and Wenbing Tao **SSRNet: Scalable 3D Surface Reconstruction Network** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Mi_SSRNet_Scalable_3D_Surface_Reconstruction_Network_CVPR_2020_paper.pdf) - Kyungjae

2. Zhiqin Chen, Andrea Tagliasacchi, Hao Zhang **BSP-Net: Generating Compact Meshes via Binary Space Partitioning** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_BSP-Net_Generating_Compact_Meshes_via_Binary_Space_Partitioning_CVPR_2020_paper.pdf)[[Code]](https://github.com/czq142857/BSP-NET-original) - Kyungjae

3. Yinyu Nie, Xiaoguang Han, Shihui Guo, Yujian Zheng, Jian Chang, Jian Jun Zhang **Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes from a Single Image** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Nie_Total3DUnderstanding_Joint_Layout_Object_Pose_and_Mesh_Reconstruction_for_Indoor_CVPR_2020_paper.pdf) - Kyungjae

4. Sicheng Xu, Jiaolong Yang, Dong Chen, Fang Wen, Yu Deng, Yunde Jia, Xin Tong **Deep 3D Portrait from a Single Image** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Xu_Deep_3D_Portrait_From_a_Single_Image_CVPR_2020_paper.pdf) - Seunggyu

5. Hamid Izadinia, Steven M. Seitz **Scene Recomposition by Learning-Based ICP** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Izadinia_Scene_Recomposition_by_Learning-Based_ICP_CVPR_2020_paper.pdf) - Seunggyu

### Motion and Tracking ###

1. Enric Corona, Albert Pumarola, Guillem Aleny√†, Francesc Moreno-Noguer **Context-Aware Human Motion Prediction** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Corona_Context-Aware_Human_Motion_Prediction_CVPR_2020_paper.pdf) [[Video]](http://cvpr20.com/event/context-aware-human-motion-prediction/) - Seunggyu

2. Bardia Doosti, Shujon Naha, Majid Mirbagheri, David J. Crandall **HOPE-Net: A Graph-Based Model for Hand-Object Pose Estimation** [[Paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Doosti_HOPE-Net_A_Graph-Based_Model_for_Hand-Object_Pose_Estimation_CVPR_2020_paper.pdf) [[Video]](http://cvpr20.com/event/hope-net-a-graph-based-model-for-hand-object-pose-estimation/)-Seunggyu

